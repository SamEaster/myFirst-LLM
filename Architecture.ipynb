{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573856c9-b8fb-473b-8b28-f3ce5dbb6380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f6c206-a110-4c04-98d5-8cd427c5fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_config_124m = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layer\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf309d0-3515-4886-b1f3-47daa69fe746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get('https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch02/01_main-chapter-code/the-verdict.txt')\n",
    "raw_text = response.text\n",
    "print(raw_text[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2edc1c48-7c2c-4c32-9c1a-48047a767787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20479"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd38ed6-d5d0-402d-8835-eb859cbbf029",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed617412-027a-4cc0-b4d9-cdce05f261b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like the tea? <|eos|> In the sunlight abouve theearth\n",
      "[15496, 11, 466, 345, 588, 262, 8887, 30, 1279, 91, 68, 418, 91, 29, 554, 262, 19606, 450, 280, 303, 262, 16442]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello, do you like the tea? <|eos|> In the sunlight abouve theearth'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"Hello, do you like the tea?\"\n",
    "text2 = \"In the sunlight abouve theearth\"\n",
    "\n",
    "text = \" <|eos|> \".join((text1,text2))\n",
    "print(text)\n",
    "tokens = tokenizer.encode(text, allowed_special={'<|eos|>'})\n",
    "print(tokens)\n",
    "print()\n",
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d982a286-a896-4357-a684-64c2237d537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229],\n",
      "        [-0.1863,  2.2082, -0.6380,  0.4617,  0.2674]])\n",
      "tensor([[0.0000, 0.1842, 0.0052, 0.7233, 0.0000, 0.5298],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2237, 0.0000, 0.7727]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_example = torch.randn(2, 5)\n",
    "print(batch_example)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bee5401-f786-4a23-b582-badc8a643afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  tensor([[0.2404],\n",
      "        [0.1661]], grad_fn=<MeanBackward1>)\n",
      "Var tensor([[0.0982],\n",
      "        [0.0963]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True) # dim=-1 refer to last dim\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Var\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d5bcaf1-941b-4bce-bba1-aa2f88017cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00],\n",
      "        [1.4901e-08]], grad_fn=<MeanBackward1>)\n",
      "tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out-mean)/torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim = True)\n",
    "var = out_norm.var(dim=-1, keepdim = True)\n",
    "print(mean)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10f304e-8324-41e2-8864-88658ee73e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out%num_heads==0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out//num_heads\n",
    "        \n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "    \n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "    \n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "    \n",
    "            # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "    \n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "    \n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "    \n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "            \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "    \n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "            \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0099aed-4789-4cb9-b9ce-fe80129c2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        out_norm = (x-mean)/torch.sqrt(var+self.eps)\n",
    "        return self.scale * out_norm + self.shift\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20caf2ea-2339-4053-9e49-3eca52bb2f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-1.1921e-08],\n",
      "        [ 3.2037e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(5)\n",
    "out = ln(batch_example)\n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c3837c-6e69-4a3d-a9d6-5d218080842c",
   "metadata": {},
   "source": [
    "# FeedForward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ae61cf3-1337-4de2-8fdf-bd42882c38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GeLU(x):\n",
    "#     return .5*x*(1+torch*tanh(\n",
    "#         torch.sqrt(torch.tensor(2.0 / torch.pi))*(x+.044715*torch.pow(x,3))\n",
    "#     ))\n",
    "\n",
    "class GELU(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return .5*x*(1+torch.tanh(\n",
    "        torch.sqrt(torch.tensor(2.0 / torch.pi))*(x+.044715*torch.pow(x,3))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9319f7e0-d824-468a-a79f-d3213cbd649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baa599ee-926c-4e4c-85da-89dcec460ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4*cfg['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg['emb_dim'], cfg['emb_dim'])\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f0e0083-e3c3-4e42-b32e-99539f5ba138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ff = FeedForward(gpt_config_124m)\n",
    "x = torch.randn(2, 3, 768)\n",
    "op = ff(x)\n",
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8075d8-b4ea-4856-b2ae-b8eb36d359d6",
   "metadata": {},
   "source": [
    "# Residual Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80f6cab7-6d71-4c23-b72f-1bc9fe48d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            op = layer(x)\n",
    "            if self.use_shortcut and x.shape == op.shape:\n",
    "                x = x + op\n",
    "            else:\n",
    "                x = op\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "890bca9f-93a0-496e-96ce-9d4ea0728540",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[2., 0., -2.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aafcb34d-e53b-4391-b5ff-3eee67550075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.0]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            print(f\"{name} gradient is {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a61f7d0d-b5fe-41af-8d99-d9a016228841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight gradient is 0.00035526571446098387\n",
      "layers.1.0.weight gradient is 0.0001255692186532542\n",
      "layers.2.0.weight gradient is 0.0006820476846769452\n",
      "layers.3.0.weight gradient is 0.001428114715963602\n",
      "layers.4.0.weight gradient is 0.005130246747285128\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9d7702f-7fd1-40a2-a7f9-b01e9e0be226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight gradient is 0.020357703790068626\n",
      "layers.1.0.weight gradient is 0.05884631350636482\n",
      "layers.2.0.weight gradient is 0.09979002922773361\n",
      "layers.3.0.weight gradient is 0.1233186200261116\n",
      "layers.4.0.weight gradient is 0.6515035033226013\n"
     ]
    }
   ],
   "source": [
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d363336-8a85-4d52-b88b-d5d86b45144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg['emb_dim'],\n",
    "            d_out = cfg['emb_dim'],\n",
    "            context_length = cfg['context_length'],\n",
    "            num_heads = cfg['n_heads'],\n",
    "            dropout = cfg['drop_rate'],\n",
    "            qkv_bias = cfg['qkv_bias'])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 =  LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 =  LayerNorm(cfg['emb_dim'])\n",
    "        self.drop_shortcut = nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        ip = x.clone()\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x = self.att(x)\n",
    "\n",
    "        x = self.drop_shortcut(x)\n",
    "\n",
    "        x = ip+x\n",
    "        \n",
    "        ip = x.clone()\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        x = self.ff(x)\n",
    "\n",
    "        x = self.drop_shortcut(x)\n",
    "\n",
    "        x = x+ip\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3ed6ed0-7888-46d5-90c8-85cb15abc536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768) #A\n",
    "block = TransformerBlock(gpt_config_124m)\n",
    "op = block(x)\n",
    "print()\n",
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fb094ca-b9ac-4794-8396-820b62e7fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(12)]\n",
    "        )\n",
    "        self.final_norm = nn.LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias = False)\n",
    "        \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        # print(in_idx.shape)\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device = in_idx.device))\n",
    "        x = tok_embeds+pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "487387be-6703-4546-b2da-0dab846ea65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20308,   148, 46900,  6624],\n",
       "        [24359, 14733, 16200, 48499]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_example = torch.randint(gpt_config_124m['vocab_size'], (2, 4))\n",
    "batch_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c7d6c55-7311-4df4-a96f-60484f4d4ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[20308,   148, 46900,  6624],\n",
      "        [24359, 14733, 16200, 48499]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.0778, -0.4861, -0.0606,  ...,  0.7088,  0.5660, -0.6934],\n",
      "         [-0.4017, -0.4462, -0.2100,  ..., -0.0318,  0.4619, -0.0037],\n",
      "         [ 0.9630,  0.4658, -0.3201,  ...,  0.1911, -0.3700,  0.3248],\n",
      "         [ 0.0315, -0.5660,  0.3238,  ...,  0.4954,  0.0469, -0.1438]],\n",
      "\n",
      "        [[-1.0713, -1.2270,  0.5332,  ..., -0.0138, -0.0318, -0.4353],\n",
      "         [ 0.3433, -0.3304, -0.6242,  ..., -0.0972,  0.7364, -0.3323],\n",
      "         [ 1.1776,  1.1702, -0.8074,  ...,  0.6041, -0.4844, -0.2060],\n",
      "         [-0.6041,  0.3814, -0.2816,  ...,  0.9188,  0.0709,  0.0776]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(gpt_config_124m)\n",
    "out = model(batch_example)\n",
    "print(\"Input batch:\\n\", batch_example)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "570ee066-1b7e-4880-ab63-f0ec88b21122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_config_124m['context_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d742f346-5663-4ede-bf38-5a9016ce1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # a = logits[-1, :, :]\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        \n",
    "        idx = torch.cat((idx,idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f0386a3-de54-40e3-bcac-779a25e48a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 314, 716]\n",
      "tensor([[15496,    11,   314,   716]])\n"
     ]
    }
   ],
   "source": [
    "start_content = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_content)\n",
    "print(encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(encoded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0261406-02b8-4afc-843e-a2e4d95e70d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "op = generate_text_simple(model=model, idx= encoded_tensor, max_new_tokens=6, context_size=gpt_config_124m['context_length'])\n",
    "print(op.shape)\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea22a228-5f0a-4d94-ab51-3c23fb372fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 384,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9d4167f2-52cc-4674-b69e-f652b5241def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "text_op = tokenizer.decode(op.squeeze(0).tolist())\n",
    "print(text_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "39a67c54-5ecb-48a8-808c-4818c901d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoder = tokenizer.encode(text, allowed_special = {'|<endoftext>|'})\n",
    "    encoder_tensor = torch.tensor(encoder).unsqueeze(0)\n",
    "    return encoder_tensor\n",
    "\n",
    "def token_ids_to_text(tokens, tokenizer):\n",
    "    decoder = tokenizer.decode(tokens.squeeze(0).tolist())\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cbce00a5-c3a8-4eca-bb6f-33e11c8095a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you 320 {\" Happy dot cornerstoneratomSTER sob Bordmn\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=gpt_config_124m[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a44bc49e-dd01-4440-84e1-1cb2c0d71493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1256]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_token_ids(\" lot\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2c3f2618-f321-447c-b919-203e58f8eba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' you'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6884ffe1-4dec-44be-b264-0780d20e7165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'every effort moves you'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(torch.tensor([16833, 3626, 6100, 345]), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cad13edc-e042-4559-bcc5-1d89fa6d0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100, 345],   # [\"every effort moves you\",\n",
    "                       [40,    1107, 588, 11311]])   #  \"I really like chocolate\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345, 2651],  # [\" effort moves you forward\",\n",
    "                        [1107,  588, 11311, 1256]]) # really like chocolate lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "89996218-d2c3-4e6a-861d-54e6d7bbe624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "439beb81-91e6-4ed2-949a-8786da2c1b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[38919],\n",
      "         [12468],\n",
      "         [11140],\n",
      "         [20959]],\n",
      "\n",
      "        [[16692],\n",
      "         [29294],\n",
      "         [ 2221],\n",
      "         [44062]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a3b7dd88-1f3f-4931-9b98-8e0e0f2d24d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you forward\n",
      "Outputs batch 1:  OstWork Search 320\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a91a4839-0574-444e-ac16-fe906c205e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 50257])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([8, 50257])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "target_flat = targets.flatten()\n",
    "\n",
    "print(logits.shape)\n",
    "print(targets.shape)\n",
    "print(logits_flat.shape)\n",
    "print(target_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e0f94530-14a3-49b3-8138-d2756887e6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9016)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, target_flat)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "374f7998-b362-4651-b94e-3b780c6de2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(54262.1250)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefcac39-6868-49d8-a5f1-dfec7902bfd6",
   "metadata": {},
   "source": [
    "# Data-Loading and Model Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f96ac006-801e-4df9-b128-abc906191dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get('https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch02/01_main-chapter-code/the-verdict.txt')\n",
    "raw_text = response.text\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d0a2d275-9bbf-4d8c-89e0-d5c225f743a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char:  20479\n",
      "tokens:  5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(raw_text)\n",
    "total_tokens = len(tokenizer.encode(raw_text))\n",
    "\n",
    "print(\"Char: \", total_characters)\n",
    "print(\"tokens: \", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "0a3b1fdb-32c0-408d-806e-e834d160347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/shubham/Desktop/Projects/Text_Summarizer/NewsDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "1c7bfe53-1984-4593-8f61-23e667f8437a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Celeb chef Anthony Bourdain wins multiple Emmy...</td>\n",
       "      <td>Celebrity chef Anthony Bourdain, who passed aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clearly something is wrong with US, says JPMor...</td>\n",
       "      <td>World's most valuable bank JPMorgan Chase's CE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two more allegedly commit suicide over Maratha...</td>\n",
       "      <td>Two more people have allegedly committed suici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Must curb hate speeches during poll campaigns:...</td>\n",
       "      <td>A group of former chief election commissioners...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PNB to block all Maestro debit cards from July 31</td>\n",
       "      <td>Punjab National Bank (PNB) Maestro debit card ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary  \\\n",
       "0  Celeb chef Anthony Bourdain wins multiple Emmy...   \n",
       "1  Clearly something is wrong with US, says JPMor...   \n",
       "2  Two more allegedly commit suicide over Maratha...   \n",
       "3  Must curb hate speeches during poll campaigns:...   \n",
       "4  PNB to block all Maestro debit cards from July 31   \n",
       "\n",
       "                                                Text  \n",
       "0  Celebrity chef Anthony Bourdain, who passed aw...  \n",
       "1  World's most valuable bank JPMorgan Chase's CE...  \n",
       "2  Two more people have allegedly committed suici...  \n",
       "3  A group of former chief election commissioners...  \n",
       "4  Punjab National Bank (PNB) Maestro debit card ...  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "b5b1e753-5b5f-4934-93eb-de8f52388ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "punch = string.punctuation\n",
    "punch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "59e06f37-31da-404e-90bd-f8f67c68748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summ(text):\n",
    "    new_text = re.sub(r\"'s\\b\", \"is\", text)\n",
    "    new_text = re.sub(r'<.*?>',' ',new_text)\n",
    "    new_text = re.sub(r'https?://\\S+|www\\.\\S+','',new_text)\n",
    "    new_text = re.sub('@[A-Za-z0-9]+',' ',new_text)\n",
    "    new_text = re.sub(r\"[^a-zA-Z]\", \" \", new_text)\n",
    "#     new_text = re.sub(r'\\b(\\w+)(?:\\W+\\1\\b)+',r\"\\1\", new_text)\n",
    "    new_text = re.sub(r'(.)\\1{2,}', r'\\1\\1', new_text)\n",
    "    new_text.translate(str.maketrans('','',punch))\n",
    "\n",
    "    newString= ''\n",
    "    for i in new_text.split():\n",
    "        if len(i)>1:\n",
    "            newString=newString+i+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "ba4900a2-a9c8-46de-a919-89363c034f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "8c002df8-55b8-4ee2-b8dc-87fd4258fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['summ'] = df['Summary'].apply(summ)\n",
    "dt['text'] = df['Text'].apply(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "a891c695-e236-4c89-bb3c-c9675983f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "# train_data = \"\"\n",
    "# val_data = \"\"\n",
    "for i, row in dt[:len(dt)//4].iterrows():\n",
    "    text += row.values[0]+ \" \"+row.values[1]\n",
    "    # train_data += row.values[1]\n",
    "    # val_data += row.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "660ab00a-db4e-481b-8d8e-4ecb43d79025",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_characters = len(text)\n",
    "total_tokens = len(tokenizer.encode(text))\n",
    "\n",
    "print(\"Char: \", total_characters)\n",
    "print(\"tokens: \", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af192f56-6a6e-4dd4-b22b-8bc95d048c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "b2abfadf-e7e6-4fe1-9aed-be661e34d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text))\n",
    "train_data = text[:split_idx]\n",
    "val_data = text[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "aa11d338-e47d-4533-8ae8-3fe077b957fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8969890, 1551718)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data) #38179433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "e9697a18-69b5-4857-acfc-3121cf390ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "67a0edd1-0ee8-4225-8b87-e527286318bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "9d573840-011a-44c5-b025-4dc47a207ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=64,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=64,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "cd9e4ef2-a81d-40cf-b41a-08c64b218784",
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "97c84da9-c2dc-4bcb-a123-c279583e7750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([64, 256]) torch.Size([64, 256])\n",
      "torch.Size([61, 256]) torch.Size([61, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "480ae7fb-cb8b-4e96-8df8-b1c13fbfac60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1687552\n",
      "310528\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for inputs_batch, target_batch in train_loader:\n",
    "    train_tokens += inputs_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for inputs_batch, target_batch in val_loader:\n",
    "    val_tokens += inputs_batch.numel()\n",
    "\n",
    "print(train_tokens)\n",
    "print(val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "e6fb847a-6566-4453-891f-68b8867e9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    # print(logits.flatten(0, 1).shape)\n",
    "    # print(target_batch.flatten().shape)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader)==0:\n",
    "        return float(\"nan\")\n",
    "        \n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "        \n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "        \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i<num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "e9ff565b-e5b4-450d-92b7-d5abc7502dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "# elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "47d96fc7-04fd-49f3-885b-584592ecf44b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 384)\n",
       "  (pos_emb): Embedding(256, 384)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_key): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (W_value): Linear(in_features=384, out_features=384, bias=False)\n",
       "        (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  (out_head): Linear(in_features=384, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "f4af4193-1433-440e-8140-32d068fd99b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: tensor(10.7881)\n"
     ]
    }
   ],
   "source": [
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=1)\n",
    "    # val_loss = calc_loss_loader(val_loader, model, device, num_batches=1)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "# print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "5157983f-d745-450e-8a8f-e7600df724f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(train_loader, val_loader, model, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, eval_iter)\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52304a1-d78d-41b8-8532-72fab49ef974",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "92f278b7-7456-45f1-b4e6-34ea8bccbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, epoches, \n",
    "                      eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, token_seens = [], [], []\n",
    "    global_step=1\n",
    "    for epoch in range(epoches):\n",
    "        model.train()\n",
    "        \n",
    "        for train_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(train_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            token_seen+=train_batch.numel()\n",
    "            global_step +=1\n",
    "\n",
    "            if global_step%eval_freq==0:\n",
    "                train_loss, val_loss =evaluate_model(train_loader, val_loader, model, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                token_seens.append(token_seens)\n",
    "                print(f\"For the epoch {epoch}, {global_step}: train_loss: {train_loss:.4f} and val_loss: {val_loss:.4f}\")\n",
    "\n",
    "        # start_context = \"Every effort moves you\"\n",
    "        model.eval()\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=text_to_token_ids(start_context, tokenizer),\n",
    "            max_new_tokens=50,\n",
    "            context_size=gpt_config_124m[\"context_length\"]\n",
    "        )\n",
    "        \n",
    "        print(\"Output text: \", token_ids_to_text(token_ids, tokenizer).replace(\"\\n\", \" \"))\n",
    "        print()\n",
    "    return train_losses, val_losses, token_seens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "064d7ee6-65af-444d-ad51-8b2cafb21324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the epoch 0 train_loss: 9.389822006225586 and val_loss: 9.481074333190918\n",
      "Output text:  Every effort moves you, the, the, the,, the the,,, the, the, the,,, the the,,,, the, the,, the the,, the,,, the, the the, the,, the the\n",
      "\n",
      "For the epoch 1 train_loss: 8.41596508026123 and val_loss: 8.597633361816406\n",
      "For the epoch 1 train_loss: 7.382205009460449 and val_loss: 7.696166038513184\n",
      "Output text:  Every effort moves you, the, the, the,, the the,,, the,, the,,,,, the,,,, the, the,, the,,,,,,, the, the,,,,, the,\n",
      "\n",
      "For the epoch 2 train_loss: 6.581667423248291 and val_loss: 7.050644397735596\n",
      "For the epoch 2 train_loss: 6.105190277099609 and val_loss: 6.703143119812012\n",
      "Output text:  Every effort moves you, the, the, the, I.                                         \n",
      "\n",
      "For the epoch 3 train_loss: 5.528920650482178 and val_loss: 6.579864978790283\n",
      "For the epoch 3 train_loss: 5.329677104949951 and val_loss: 6.414705276489258\n",
      "Output text:  Every effort moves you the he was, and the, and I had, and I had the-- to have to have to the to have of the. \"-- of the the to to the. I had to the, and he had the, and I had\n",
      "\n",
      "For the epoch 4 train_loss: 4.853481769561768 and val_loss: 6.277701377868652\n",
      "For the epoch 4 train_loss: 4.55222225189209 and val_loss: 6.216121673583984\n",
      "Output text:  Every effort moves you.     I--I--I, and--I--I, I had a, in the, and.                 \"--I, I had\n",
      "\n",
      "For the epoch 5 train_loss: 4.21354341506958 and val_loss: 6.193042755126953\n",
      "Output text:  Every effort moves you know I was not that he had been a he had been a--I--I had been to have to have, I had been, a.     \"--as--I, and in the, and, and I.\n",
      "\n",
      "For the epoch 6 train_loss: 3.9646899700164795 and val_loss: 6.144447326660156\n",
      "For the epoch 6 train_loss: 3.584451198577881 and val_loss: 6.136855602264404\n",
      "Output text:  Every effort moves you know I had been a little, and I felt, and. Gisburn.   \"--and, I had a little a. \"--I had the. \"--the, and in the--as, and I had\n",
      "\n",
      "For the epoch 7 train_loss: 3.293581485748291 and val_loss: 6.075954437255859\n",
      "For the epoch 7 train_loss: 2.9331579208374023 and val_loss: 6.087628364562988\n",
      "Output text:  Every effort moves you.  \"--and I had a little that, and his of a.    \"Oh, I had to see a. It was his own, he had been his painting, in a, and he--as I had\n",
      "\n",
      "For the epoch 8 train_loss: 2.620854616165161 and val_loss: 6.1298956871032715\n",
      "For the epoch 8 train_loss: 2.398477792739868 and val_loss: 6.149297714233398\n",
      "Output text:  Every effort moves you on the, and in the picture. Gisburn. \"I turned back to my work, and in a, and. It was, and in a _not, I had been his own a, and: \"Be dissatisfied with his\n",
      "\n",
      "For the epoch 9 train_loss: 2.0687143802642822 and val_loss: 6.138998031616211\n",
      "For the epoch 9 train_loss: 1.8384946584701538 and val_loss: 6.167106628417969\n",
      "Output text:  Every effort moves you?\"  \" a little.\" \"-- his, a single one in the house.\" \"--and that, and a little a. It was his glory, he had always--the him, a rich; and Mrs. Gis\n",
      "\n",
      "For the epoch 10 train_loss: 1.5496656894683838 and val_loss: 6.1738786697387695\n",
      "Output text:  Every effort moves you know I meant to do the picture for nothing--I told Mrs. Stroud so when she began to me!    I moved, and his close grayish beard--as if he had the donkey. \"strongest,\" she said\n",
      "\n",
      "For the epoch 11 train_loss: 1.349875807762146 and val_loss: 6.216392517089844\n",
      "For the epoch 11 train_loss: 1.0791627168655396 and val_loss: 6.2231011390686035\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him, and in an exquisburn, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 12 train_loss: 0.9247997403144836 and val_loss: 6.264265537261963\n",
      "For the epoch 12 train_loss: 0.7501803040504456 and val_loss: 6.336136817932129\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 13 train_loss: 0.6027446389198303 and val_loss: 6.297524452209473\n",
      "For the epoch 13 train_loss: 0.49887070059776306 and val_loss: 6.372589588165283\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  \"Oh, in the height of his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 14 train_loss: 0.41594046354293823 and val_loss: 6.388030529022217\n",
      "For the epoch 14 train_loss: 0.3119266629219055 and val_loss: 6.401123523712158\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 15 train_loss: 0.2505921721458435 and val_loss: 6.433690071105957\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 16 train_loss: 0.2081192433834076 and val_loss: 6.514871120452881\n",
      "For the epoch 16 train_loss: 0.17522475123405457 and val_loss: 6.533179759979248\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 17 train_loss: 0.1670316904783249 and val_loss: 6.542936325073242\n",
      "For the epoch 17 train_loss: 0.13980236649513245 and val_loss: 6.5456366539001465\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 18 train_loss: 0.12271569669246674 and val_loss: 6.587275981903076\n",
      "For the epoch 18 train_loss: 0.10762502998113632 and val_loss: 6.630096912384033\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 19 train_loss: 0.09291698038578033 and val_loss: 6.6575117111206055\n",
      "For the epoch 19 train_loss: 0.07428650557994843 and val_loss: 6.65846586227417\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 20 train_loss: 0.0736614316701889 and val_loss: 6.632324695587158\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 21 train_loss: 0.06207801774144173 and val_loss: 6.746614933013916\n",
      "For the epoch 21 train_loss: 0.05992128327488899 and val_loss: 6.722937107086182\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 22 train_loss: 0.050105951726436615 and val_loss: 6.721120834350586\n",
      "For the epoch 22 train_loss: 0.04662065953016281 and val_loss: 6.713726043701172\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 23 train_loss: 0.043315339833498 and val_loss: 6.753076076507568\n",
      "For the epoch 23 train_loss: 0.040281977504491806 and val_loss: 6.768675327301025\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 24 train_loss: 0.03567419573664665 and val_loss: 6.763127326965332\n",
      "For the epoch 24 train_loss: 0.03174029663205147 and val_loss: 6.822861671447754\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 25 train_loss: 0.02628125250339508 and val_loss: 6.802453517913818\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 26 train_loss: 0.02570568025112152 and val_loss: 6.8248419761657715\n",
      "For the epoch 26 train_loss: 0.021952057257294655 and val_loss: 6.830315589904785\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 27 train_loss: 0.020030522719025612 and val_loss: 6.834125518798828\n",
      "For the epoch 27 train_loss: 0.019653845578432083 and val_loss: 6.845914840698242\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 28 train_loss: 0.016069874167442322 and val_loss: 6.857179164886475\n",
      "For the epoch 28 train_loss: 0.017397332936525345 and val_loss: 6.890764236450195\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 29 train_loss: 0.015160752460360527 and val_loss: 6.887821674346924\n",
      "For the epoch 29 train_loss: 0.01574968546628952 and val_loss: 6.860491752624512\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "For the epoch 30 train_loss: 0.01529228687286377 and val_loss: 6.892943382263184\n",
      "Output text:  Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "\n",
      "time taken is : 6.27\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_t = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0004, weight_decay=0.08)\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "train_losses, val_losses, token_steps = train_model_simple(model, train_loader, val_loader, optimizer, device, 31, \n",
    "                5, 5, start_context, tokenizer)\n",
    "\n",
    "time_taken = (time.time() - start_t)/60\n",
    "print(f\"time taken is : {time_taken:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "32ff3d3c-939a-4916-b50d-80c95df0dcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3e51237a0>]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4CUlEQVR4nO3dd3hUZfrG8XtSSSAJHUQCIipFilIERLCj6CoWUBT7b1dBLMi6K4iKiBqsa1txUZfVRQRXsdcoTUAUBARBQUAp0hGSEELq+f3xMCmQQBJm5kz5fq7rvc6ZSZnHY8jcec9bPI7jOAIAAPCBKLcLAAAA4YNgAQAAfIZgAQAAfIZgAQAAfIZgAQAAfIZgAQAAfIZgAQAAfIZgAQAAfCYm0C9YVFSkTZs2KSkpSR6PJ9AvDwAAqsFxHGVlZalJkyaKiqq4XyLgwWLTpk1KTU0N9MsCAAAf2LBhg5o2bVrhxwMeLJKSkiRZYcnJyYF+eQAAUA2ZmZlKTU0tfh+vSMCDhff2R3JyMsECAIAQc7hhDAzeBAAAPkOwAAAAPkOwAAAAPkOwAAAAPkOwAAAAPkOwAAAAPkOwAAAAPkOwAAAAPkOwAAAAPkOwAAAAPkOwAAAAPkOwAAAAPhMewWLfPunZZ6UBA6T8fLerAQAgYoVHsIiNlR56SHr7bWnBArerAQAgYoVHsIiOls4+286//NLdWgAAiGBhESyKiqR1x58jSXIIFgAAuCYsgkVBgdT3KQsW+uYbac8edwsCACBChUWwiIuTGp96rNaqhTwFBdKsWW6XBABARAqLYCFJvXtLX2p/rwW3QwAAcEVYBgvGWQAA4I6wCRbdu0uzo89SkTzy/PijtGWL2yUBABBxwiZYJCZKx55SX4t1sj3x1VfuFgQAQAQKm2AhMc4CAAC3hVWw6NWrVLBIT5ccx92CAACIMGEVLHr2lObqNO1TvPT779LKlW6XBABARAmrYFG7ttTqpATNVU97gtshAAAEVFgFC4lxFgAAuCksg0W6zrUHM2bYet8AACAgwi5Y9OolLdbJ+kN1pMxMaeFCt0sCACBihF2waNhQOr5VtKbrLHuC2yEAAARM2AUL6YBxFunp7hYDAEAECf9gwTbqAAAETNgGizVqqd/UXMrPl77+2u2SAACICGEZLJo1k5o395TMDmGcBQAAARGWwUJiPQsAANwQtsGiVy+VzAxZulTautXdggAAiABhGyx695Z2qIGWeE6yJ9hGHQAAvwvbYHHCCbamRbrD7RAAAAIlbIOFx1POOAu2UQcAwK/CNlhIFiy+Vi/le+KkDRukX35xuyQAAMJa2AeLHCVqXhTbqAMAEAhhHSzatZNq15Y+L2ScBQAAgRDWwSI6WurZs9Q4i+nTpcJCd4sCACCMhXWwkOx2yPfqrOyYFCkjg23UAQDwo4gIFkWK1owotlEHAMDfwj5YdOokJSZKn+Ttvx3CQlkAAPhN2AeLuDipRw/pK51tT8ybJ+XkuFsUAABhKuyDhWS3Q1bpBP2R0ETKzZXmznW7JAAAwlJEBItevSTJo+neXovp090sBwCAsBURwaJbNyk2VvowZ3+wYJwFAAB+ERHBIjFR6tq11DiLhQul3btdrQkAgHAUEcFCstshv6uptiSfIBUVSbNmuV0SAABhJ2KCRc/924XM9K5nwe0QAAB8LmKCRY8ednx7N+MsAADwl4gJFvXrS61aSTN0phyPR1qxQtqyxe2yAAAIKxETLCTp1FOlP1RPmxueZE8w7RQAAJ+KuGAhSbPjuB0CAIA/RFSw8A7gfHNrqWDhOO4VBABAmImoYNGqlVSnjvRV3mkqio6R1q2T1q51uywAAMJGRAWLqCibHZKtWtrcvLs9yTgLAAB8JqKChVQyzuKbBMZZAADgaxEXLIrHWWwrtSFZUZF7BQEAEEaqFCwKCgp03333qUWLFkpISNCxxx6rhx56SEUh9MbctasUHS19uL2bihISpe3bpR9/dLssAADCQpWCxWOPPaaXXnpJL7zwgn766Sc9/vjjeuKJJ/T888/7qz6fq1lTOukkKV9x2npCL3uS2yEAAPhElYLFN998o379+unCCy/UMccco/79+6tPnz5auHChv+rzC+84i+9qMc4CAABfqlKwOO200/TVV19p1apVkqQffvhBc+bM0QUXXFDh1+Tm5iozM7NMc5t3nMVbf+wPFrNmSfn57hUEAECYqFKwuOeee3TVVVepdevWio2N1cknn6xhw4bpqquuqvBr0tLSlJKSUtxSU1OPuOgj5e2xeGvlSXLq1pX27JFCrNcFAIBgVKVgMXXqVE2aNEmTJ0/WokWL9Nprr+nJJ5/Ua6+9VuHXjBw5UhkZGcVtw4YNR1z0kUpNlZo2lQqKorSj3Zn2JLdDAAA4YlUKFn/72980YsQIDRw4UO3bt9e1116ru+66S2lpaRV+TXx8vJKTk8u0YODttfi+NuMsAADwlSoFi7179yoqquyXREdHh9R0Uy/vOItpu8+yk3nzpL173SsIAIAwUKVgcdFFF+mRRx7Rxx9/rN9++03vvvuunn76aV166aX+qs9vvD0Wby89Qc7RR0t5eRYuAABAtVUpWDz//PPq37+/br31VrVp00Z33323brnlFo0dO9Zf9flNx45SQoK0a7dHGV24HQIAgC94HCew+4ZnZmYqJSVFGRkZro+3OOMMm2k686bXdfq/r7dlOb/7ztWaAAAIRpV9/464vUJK846zeH/P/h6L77+Xdu92rR4AAEJdRAcL7ziLT344WmrVyjYjmznT1ZoAAAhlER0sune348qVUs6p+2eHMM4CAIBqi+hgUa+e1Lq1nS9vtP92yBdfSIEddgIAQNiI6GAhlYyz+GjfOVJ8vLRqlbR4sbtFAQAQoiI+WHjHWcxYlCJdfLE9+O9/3SsIAIAQRrDwbqH+nVRw9XX2YPJkqaDAvaIAAAhRER8sTjhBqltX2rdPWtLoPKlBA2nbNhtrAQAAqiTig0VUVEmvxZxvY6WBA+0Bt0MAAKiyiA8WUkmwmDdP0rXX2oP33pMyM90qCQCAkESwUEmwmDtXcjp3sTmo+/ZJb7/tbmEAAIQYgoVsi5CYGGnTJmnDRk9JrwW3QwAAqBKChaTEROnkk+187lxJgwbZg5kzpXXr3CoLAICQQ7DYr8w4i+bNbetTSXrjDbdKAgAg5BAs9is9zkJS2dshLPENAEClECz2693bjosXS1u3SurfX6pRQ/r5Z9tOHQAAHBbBYr/GjaXOne38008lJSdLl1xiTzCIEwCASiFYlHLhhXb8+OP9T3hvh7z5ppSf70pNAACEEoJFKd5g8fnnUl6epD59pIYNpe3b7UkAAHBIBItSunSxHJGVJc2ZI1vc4uqr7YPcDgEA4LAIFqVERUkXXGDnB90Oef99afduN8oCACBkECwOcNA4i5NPltq2lXJzWeIbAIDDIFgc4Nxz7Q7IypXS6tWSPCzxDQBAZREsDpCSIvXqZefFvRaDBlnAmD1b+u03t0oDACDoESzK8ac/2bE4WKSmSmeeaeeTJrlSEwAAoYBgUQ7vOItZs6Q9e/Y/yRLfAAAcFsGiHCecILVsaWtZfPnl/icvv1xKSJBWrSrVlQEAAEojWJTD4ynptfjoo/1PJiVJt95q57fcIu3a5UptAAAEM4JFBbzjLD75pNSdj7FjrTtj0ybpjjtcqw0AgGBFsKhA795SzZrS5s2246kkuxXy2mu2ktakSdK777paIwAAwYZgUYH4eFvTQjpgSEX37tLf/27nt9xi+4gAAABJksdxAjvFITMzUykpKcrIyFBycnIgX7rKXnlF+stfpFNOkb79ttQHcnNtY5Eff5T695feessGZgAA4FVQIK1fL/3yi624uHq1lJkpRUdX3GrUkJo2lZo1s5aaat3n5XEcaccOac0aa6tX2/G336QZM+z7+VBl378JFoewaZN09NGWGbZssQ3Kii1aJHXrZj84b74pDRzoWp0AAD9zHGnvXluD4MCWlWXHjAzp11/tDf6XX+w8P//IX7tu3ZKgcfTRFia8ISIzs/yv+fVX6Zhjjvy1S6ns+3eMT181zDRpInXqZBni00+l668v9cFOnaT77pMefNBmi5x+unTUUW6VCgChKS/P9lCoWVNq1Kjiv87Lk5trf/Vt2SL98Yd9r0O1ggJ7oy8oKNu8z+XkWEg4sHkDRFFR1f/74uNt/YLjj5eOO06qX18qLLTXKyw8uGVnSxs3Wk/Hhg0WVv74w9qSJeW/RtOm9hrHHWfHli0tjLiEYHEYF15oweLjjw8IFpJ0773SBx/YJ9x8s51zSwQAKlZQIH3/vXXVT58uzZ1rPQFeiYnWPextjRpJDRrYm//mzRYivEe3pv3XqlW2JSWVnDdvbm/w3iDRtKkN+K+ujAwLGN6gsXGjhQZviGjRwiYWBBFuhRzGt9/aeM3kZOt9io094BN+/FHq3NnS8MSJ0g03uFEmAARGYaG92e3ebW/su3bZX/Jxcdbi40vOvW3LFgsSM2ZIX39tvQClJSfb79B9+6peT1yc1LixVK+ejU848LW9LTbWWkyMtdLn3paQUBIUSrfS4aFmzSMLCiGMMRY+UlRkP7Pbt1u49m4ZUsa4cdLIkfaP48cfbbANAFRXUZH1gK5cabdYmzQpOdau7d+e0e3bpeXLra1YYasN79xZEiIyM498W4M6dez28ZlnWjvxRPtvys6Wtm0r27ZutWNsrF2Dxo2tec/r1KGnOEAYY+EjUVHSBRfY8hUff1xBsLj7bun996X586X/+z/p88/5QQdQdQUF0pQp0qOPSj/9VP7n1KhhAaNJE7tVEBtrv6gqanFx9jWlW0JCyXlmZkmQWL688lPoExPtTb12bftr/1BjGxITbdtob5Do0KH8GQve2wnHHlvtSwj30WNRCf/7n3TFFVLr1hX/W9fKldJJJ1lX3g03SA8/bKN3AeBw8vKk11+X0tKktWvtudq1pfPPt96CTZusBWpMQYsWUtu21pPQpo0FmDp1Slrt2nbLAxGFWyE+lJFhA3kLCmyGT8uWFXziiy9KQ4faeY0adj5ihH0xgNCXlWWD6Navt18MRUV2W6C8FhNj3fWpqTaALzHx4O+3b5/06qvSY4/ZwDzJfl8MH26zzVJSyn5+To6NV/AGjW3bbMyD41gtB7bCQhv0mJNjr3Vgy8mx31Vt25YNElWZmYGIQbDwsTPPlGbOlJ599jDbhHz9tc0WmTPHHicl2S+J4cNtDAaA4JWfb2MKli2zRYa8IcI7In/37up/77p1LWB4g0ZysvTf/1pQkGy8wN/+Ziv68saOIESw8LGnnrKhFH362BCKQ3Ic6bPPpFGjSjYaqVfPBnjeemvQTQ0CItLOndIPP1hbutSOy5fbbYlDqVPHFiqqW9fGUlXU8vOl33+3QJKdXfH3S02V7rnHxmfVqOHb/0bAhwgWPvbzz9ZDGBdnv49q1arEFxUVSe+8I91/v43BkGzA1SOP2KIYDPAE/C831/4BL1tmAcJ73LSp/M+vVUtq397WIfCudlh6eeVK/eMvxXHstsnGjSXrEGzcaD0V3bpJ11xjv1iAIEew8DHHsR3TV6+2oRRDhlThiwsKrMvzwQetS1WS+vWTXn7ZFn4BcLC8PFs4KTvbmvd8796KVy30to0bLUAsW2ahvqCg/Ndo2dJmKHTsWHI85piIXacAOBSChR88/7yNr2jWzJaBr/IfGbm50j/+IT3wgHWTNmok/fvfNp8VCHeOY7caVq601eYqart2WYCoKAxUR+3aFhzaty/bkpJ89xpAmCNY+EFOjk2v3rJFmjDBdj6tliVLrPtz+XJ7fOut0hNPlD9qHAh1q1bZRn1TptgtiaqKjrbBjImJdkxIsLUbDrVDZIMGFhy8YcK7myCAaiNY+Mkzz0h33WW9patWlbPEd2Xl5NhgzmeftcetWklvvGHLgwOhbt06aepUCxPeAcySrX3QubO98devX7bVq2fHOnVKlk5OTLSuQUIB4DqChZ/s3Wtrx2zbZncxbrzxCL9herotqLVpk817HzPGRoiXtyodEIyKimxMw5o1NrPif/+T5s0r+XhMjHTuudJVV9nYohD8dw+AYOFXTz5p081btrSe3ZgjXRh9506bu/7OO/a4Z0/ppZekdu2OuFag2hzHFlHKzCxpW7dagFizxkYyr1ljK0UeOEXT47G9IAYOlC6/nEXigDBAsPCj7Gy7FbJjh+0hct11PvimjmNL+t5+u63uFx1tU0/GjLH58sCRyM+3WxLbt5dsJlW6eXeqzMgoCREZGZUfQBkba/8ojjvOFnsZMIAl7YEwQ7Dws8ces9W6jz/e9g/x2Z2L336T/vpXado0e1yvnjR2rHTzzdweQdXk5EhffGE/Sx9+WP19Jjwemz2RnGw/j8cea911xx1XckxN5ecTCHMECz/bs8f+QNu5U5o0SRo0yMcv8NVX0p13lswc6dBBeu45615GZMjLk2bPtu2zP/vM3ri9ezp4W6tWZVdrzMiwbXinTZM+/dQGBXnVq2c/tN5NpEpvKuV9rnZtCxApKXZMTraBlKzrAEQ8gkUAPPqordrdurX0449++IOtoEAaP97WvfDuUTBggE1Nbd7cxy+GoLB7twWC99+3Y2bmoT8/Ksp6ENq2tXVSpk+32x5ezZpJl14qXXaZjd2hVwFANREsAiAz0/4A3LXLpukPHOinF9qxw5YFnzDBRuAnJEgXXSSdfba1Y49lOl6oysy0VPrdd3a7YvbssuMaGjWy/9cXXWT/31esKGnLl5d/e6NNm5Iw0akTPxsAfIJgESBjx1qHQtu2tnqwX3uMlyyx2yOzZ5d9vnnzkpBx1lm2SyKCS16erTjpXWba27xLvJd24onSxRdbO+WUin+oHMfmPXuDRm6u1LevBQsA8DGCRYBkZNj7ekaGTd/v39/PL+g4tkZAerqNw5g//+CR+yeeaIsQNWkiHXXUwY0VPo+M49i6I0uXWvvxR+s52LfP3txzcw8+37mz4hkWRx9tq0P26WNhomXLwP73AEAlECwC6MEHbVZo+/bWqRDQcW579khff20h46uvrIDDSUmxUfydOkldu1rr2JEtmx2n/FCQkVGyI6a37dxZ9e+fnGw/JO3alexV0a4d04kBhASCRQDt2mVjLTIzbTD+pZe6WMyOHdLMmbZ40aZN0ubNZVtOTvlfFxNjb3TeoNGliy27nJBggaNGjeCYGVBUZAMct2+3lpFhNdasWbIMtLclJNj4gr177ZbD+vW21PS6dSXn69dbSMjNPXiRp0OJjrYZGR06WGvUyK5RfHxJK/24bl2paVPGOwAIWQSLALv/funhh6WTTpIWLQrS9w/HsfSzebMFj4ULpQULrG3ffvivj40tGzSaN5fOPNPGdXTvbm+gRyo/38YieHsGfvutJERs22bBqbCwct/L47F6S0+5rApvMKhZ08YteENEx472ONJ7eABEFIJFgO3cab0We/bYTMGLL3a7oipwHPvL3RsyFiywWyoZGdZDUBkJCdJpp1nIOOssu81S0VrnhYW2fOnu3bYmeulbDCtWlJ0uWZHkZOtRSUmx2xXZ2Xbxs7Pt8YGSkiwINWtmx9LnDRuWhAjvMTY2SNMhALjDb8Hi999/1z333KNPP/1UOTk5OuGEE/Tqq6+qcyV35QzXYCHZZqXjxklnnCHNmOF2NT5SUGC3T/btK2k5OdaWLbNxHdOnW29CacnJdjslP9+WKN+zx45ZWYfvQUhKKukdOP54e+Nv0KBsO1TvSGGhvUZ2trV69SyAEBQAoNr8Eix27dqlk08+WWeeeaaGDBmihg0bas2aNTrmmGPUspIj2cM5WGzYYL0WRUW2zHfr1m5XFCCOYz0N06db0Jg503o7Dic62paD9oYIb2venBAAAEHGL8FixIgRmjt3rr7++mu/FxaqLrnEboXceaf0zDNuV+OSwkLb8Gr5cpvampRkrVatsuc1ahAgACBE+CVYtG3bVuedd542btyoWbNm6eijj9att96qv/zlLxV+TW5urnJzc8sUlpqaGrbB4rPPbI2i2rWl339nyQgAQHiobLCo0vzBtWvXavz48Tr++OP1+eefa/Dgwbrjjjv0+uuvV/g1aWlpSklJKW6pqalVecmQ06eP1KKFjUucOtXtagAACKwq9VjExcWpS5cumjdvXvFzd9xxhxYsWKBvvvmm3K+JtB4LqWRL9VNOkb791u1qAAA4cn7psTjqqKPUtm3bMs+1adNG68vb72C/+Ph4JScnl2nh7qabbLbid9/ZmhYAAESKKgWLnj17auXKlWWeW7VqlZqzhXcZDRqU7Bny0kvu1gIAQCBVKVjcddddmj9/vh599FGtXr1akydP1oQJEzR06FB/1Reyhgyx4xtvVG7mJQAA4aBKwaJr165699139eabb6pdu3YaO3asnnnmGQ0aNMhf9YWs006zTUb37pUmTXK7GgAAAoMlvf3ohRek22+3gLFsGUs2AABCl18Gb6Jqrr3W1rFYvlyaO9ftagAA8D+ChR+lpEhXX23n48e7WwsAAIFAsPCzwYPt+PbblduZHACAUEaw8LPOnaWuXaW8PGniRLerAQDAvwgWAeDttfjXv2znUwAAwhXBIgAGDrTxFmvXSunpblcDAID/ECwCIDFRuv56O2cQJwAgnBEsAsR7O+TDD6WNG92tBQAAfyFYBEibNtLpp9sYi5dfdrsaAAD8g2ARQN79Q555RvryS1dLAQDALwgWAXTppVKvXlJmpnT++dKECW5XBACAbxEsAiguTvriC1uNs7BQuuUW6a9/tXMAAMIBwSLAatSw3U7HjLHHTz8tXXaZtGePu3UBAOALBAsXeDzSAw9Ib74pxcdLH3xg26xv2OB2ZQAAHBmChYsGDpRmzpQaNpR++EHq1k1auNDtqgAAqD6Chcu6d5e+/VZq107avFnq3Vt65x23qwIAoHoIFkHgmGOkuXOlvn2lnBxpwABp3jy3qwIAoOoIFkEiOdnGWlxxheQ40ujRblcEAEDVESyCSEyM9PjjUmysLaBFrwUAINQQLIJM8+bSDTfY+UMPuVoKAABVRrAIQiNHWu/F55/bwE4AAEIFwSIItWghXXedndNrAQAIJQSLIHXvvVJ0tPTJJ9KCBW5XAwBA5RAsglTLltKgQXY+dqy7tQAAUFkEiyA2apQUFSV9+KG0aJHb1QAAcHgEiyB2wgnSVVfZOb0WAIBQQLAIcvfdZ5uWvfee7ScCAEAwI1gEudatpSuvtHN6LQAAwY5gEQK8vRbvvCMtW+Z2NQAAVIxgEQJOPFHq39/OH37Y3VoAADgUgkWIuP9+O/7vf9KKFe7WAgBARQgWIaJ9e+myy2znU3otAADBimARQry9FlOmSD//7G4tAACUh2ARQk46SerXz3ot7rhDKix0uyIAAMoiWISYRx+VEhKk9HRpzBi3qwEAoCyCRYhp21Z6+WU7HztW+ugjd+sBAKA0gkUIGjRIuu02O7/mGmn1anfrAQDAi2ARop56SurRQ8rIkC6/XNq71+2KAAAgWISsuDhb06JhQ2npUumWW2xQJwAAbiJYhLCjj5amTpWio6VJk6Tx492uCAAQ6QgWIe6MM6THHrPzYcOk+fPdrAYAEOkIFmFg+HDbSyQ/347btrldEQAgUhEswoDHI/3737bF+u+/SwMHSgUFblcFAIhEBIswkZQkTZsm1aolzZghjRrldkUAgEhEsAgjbdpYz4UkPf649OWX7tYDAIg8BIswM2CANGSInd9wg7Rrl6vlAAAiDMEiDD3xhHT88TbeYuhQt6sBAEQSgkUYqllT+u9/bX2LN9+0bdYBAAgEgkWY6tZNuu8+Ox8yxHovAADwN4JFGBs1SuraVdq9W7rxRqmoyO2KAADhjmARxmJj7ZZIQoKUni79859uVwQACHcEizDXqpUN5pSkv/9d+uknd+sBAIQ3gkUEuPVW6bzzpH37pGuukfLy3K4IABCuCBYRwLvkd5060qJF0tixblcEAAhXBIsI0aSJ9K9/2fmjj0rffONuPQCA8ESwiCADBkiDBtnskGuvlbKy3K4IABBuCBYR5oUXpKZNpTVrpH79pJwctysCAIQTgkWEqV1bevdd2w11xgzrxcjPd7sqAEC4IFhEoC5dpI8+kmrUkD7+2G6LFBa6XRUAIBwQLCJU797StGm2iNbUqdItt0iO43ZVAIBQd0TBIi0tTR6PR8OGDfNROQikvn2lN96QoqKkV1+Vhg8nXAAAjky1g8WCBQs0YcIEdejQwZf1IMAGDJBeecXOn3lGGjPG1XIAACGuWsFiz549GjRokF5++WXVqVPH1zUhwG68UXr2WTsfM0Z66il36wEAhK5qBYuhQ4fqwgsv1DnnnHPYz83NzVVmZmaZhuBzxx3Sww/b+d13Sy+/7G49AIDQVOVgMWXKFC1atEhpaWmV+vy0tDSlpKQUt9TU1CoXicC4917bqEyywZzvvONuPQCA0FOlYLFhwwbdeeedmjRpkmrUqFGprxk5cqQyMjKK24YNG6pVKPzP45HGjZMGD7ZBnDffLO3Y4XZVAIBQ4nGcys8DeO+993TppZcqOjq6+LnCwkJ5PB5FRUUpNze3zMfKk5mZqZSUFGVkZCg5Obn6lcNv8vOlzp2lZcukG26QJk50uyIAgNsq+/5dpWCRlZWldevWlXnuxhtvVOvWrXXPPfeoXbt2PisM7vrmG+nUU+185kzp9NNdLQcA4LLKvn/HVOWbJiUlHRQeatasqXr16lUqVCB09Ohht0ImTJCGDJGWLJHi4tyuCgAQ7Fh5ExUaN05q0ED66SfpySfdrgYAEAqqdCvEF7gVElomTbK9RGrUkJYvl4491u2KAABuqOz7Nz0WOKRBg6SzzpL27ZOGDmXJbwDAoREscEgej/Tiiza+4rPPpLffdrsiAEAwI1jgsFq1kkaMsPM775RYPBUAUBGCBSpl5EjpuOOkzZul++5zuxoAQLAiWKBSatSQxo+383/+U1q40N16AADBiWCBSjvnHOnqq6WiIlv2u7DQ7YoAAMGGYIEqeeopKSVF+v57G9QJAEBpBAtUSePGkndj23vvlVascLceAEBwIVigym65RTrjDGnPHumSS6Tdu10uCAAQNAgWqLKoKOmtt6RmzaRffpGuuorxFgAAQ7BAtTRoIL33npSQYAtnjRrldkUAgGBAsEC1nXyy9Oqrdv7YY9KUKe7WAwBwH8ECR+Sqq6S//93Ob7pJWrzY3XoAAO4iWOCIPfqodP75Uk6ODebcts3tigAAbiFY4IhFR0uTJ9uS3+vXSwMGSPn5blcFAHADwQI+UaeO9P77Uq1a0uzZ0l13uV0RAMANBAv4TNu20qRJdv7Pf5YM7AQARA6CBXyqXz9pzBg7HzKEzcoAINIQLOBz991ngzjz86Ubb5Ty8tyuCAAQKAQL+FxUlDRhglS/vvTjjzZrBAAQGQgW8IsGDaTnn7fzRx6Rli1ztx4AQGAQLOA3V14pXXyxVFBgi2cVFLhdEQDA3wgW8BuPRxo/XkpJsUGc//iH2xUBAPyNYAG/atJEeuopO3/gAWnVKnfrAQD4F8ECfnfTTdI550j79kl//rNUVOR2RQAAfyFYwO88Hpslkpgoff219NJLblcEAPAXggUCokULadw4O7/nHmndOnfrAQD4B8ECATN0qNSzp7Rnj3TLLZLjuF0RAMDXCBYImKgo2z8kPl76/HPp9dfdrggA4GsECwRUq1bSgw/a+V13SVu2uFoOAMDHCBYIuLvvljp1knbtkv7yF26JAEA4IVgg4GJipIkTpbg46aOPpKefdrsiAICvECzgig4dpGeesfMRI6RvvnG1HACAjxAs4JrBg20/kYICO+7c6XZFAIAjRbCAa7wLZx1/vLRhg3TddazKCQChjmABVyUnS//7n1SjhvTJJ9ITT7hdEQDgSBAs4LqOHaXnnrPzUaOkOXPcrQcAUH0ECwSFP/9ZGjRIKiyUBg6Utm93uyIAQHUQLBAUPB7bnKxVK+n336Vrr2W8BQCEIoIFgkatWjbeIiHBlvz2bloGAAgdBAsElfbtpRdesPP775dmzXK3HgBA1RAsEHRuvLFk6umVV0o//eR2RQCAyiJYIOh4PNKLL9rqnFu3Sr17S4sXu10VAKAyCBYISjVrSl99JXXuLO3YIZ15pjRvnttVAQAOh2CBoFW/voWL006TMjKkc8+VvvzS7aoAAIdCsEBQS0mxGSLnnSft3StdeKH0/vtuVwUAqAjBAkEvMdHCxOWXS3l5dpw82e2qAADlIVggJMTHS1Om2GyRwkLpmmtsAzMAQHAhWCBkxMRIEydKQ4dKjiPdcov05JNuVwUAKI1ggZASFSU9/7w0cqQ9/tvf6LkAgGBCsEDI8XikRx+VRo+2x8OGsYgWAAQLggVC1gMP2BTUnBzp6qul3Fy3KwIAECwQsqKipP/8R6pXT1qyRLrvPrcrAgAQLBDSmjSR/v1vO3/ySRbQAgC3ESwQ8i6+WBo82M6vu07audPdegAgkhEsEBaeekpq3VravFn6859tOioAIPAIFggLiYm2GmdsrPTee9Irr7hdEQBEJoIFwsbJJ9s0VMmmoK5c6Wo5ABCRCBYIK8OHS+ecYxuWXX217S0CAAgcggXCSlSU9NprUt260qJF0v33u10RAESWKgWLtLQ0de3aVUlJSWrYsKEuueQSraS/GUGmSRPp1Vft/IknpK++crceAIgkVQoWs2bN0tChQzV//nylp6eroKBAffr0UXZ2tr/qA6rlkkukm2+22SGXXy59+63bFQFAZPA4TvUn5m3fvl0NGzbUrFmz1Lt370p9TWZmplJSUpSRkaHk5OTqvjRwWHv3SuedJ82ZIyUlSZ99Jp16qttVAUBoquz79xGNscjIyJAk1a1bt8LPyc3NVWZmZpkGBEJiovTpp9IZZ0hZWRYyZs92uyoACG/VDhaO42j48OE67bTT1K5duwo/Ly0tTSkpKcUtNTW1ui8JVFmtWtLHH9tMkT17pL59penT3a4KAMJXtW+FDB06VB9//LHmzJmjpk2bVvh5ubm5yi217WRmZqZSU1O5FYKAysmRLrvMbofUqCG9/77Up4/bVQFA6PDrrZDbb79dH3zwgWbMmHHIUCFJ8fHxSk5OLtOAQEtIsBU5//Qnad8+21/kk0/crgoAwk+VgoXjOLrttts0bdo0TZ8+XS1atPBXXYDPxcdL77wjXXqplJtrM0fef9/tqgAgvFQpWAwdOlSTJk3S5MmTlZSUpC1btmjLli3KycnxV32AT8XFSVOnSgMGSPn5Uv/+FjYAAL5RpTEWHo+n3OcnTpyoG264oVLfg+mmCAYFBdL119vGZTExUnq6zR4BAJSvsu/fMVX5pkew5AUQVGJipNdflwoLrQejf39p4ULpmGPcrgwAQht7hSBiRUdLEydKnTpJO3dK/frZlFQAQPURLBDRvLNFGjWSli6VbrjBlgEHAFQPwQIRLzXVBnDGxtrxkUfcrggAQhfBApDUs6f04ot2fv/9TEMFgOoiWAD7/fnP0m232fk110jLl7tbDwCEIoIFUMrTT0tnnmmDOPv1k/74w+2KACC0ECyAUmJjpbfesmmna9ZIV15pa14AACqHYAEcoH59G2NRs6b05ZfS3/7mdkUAEDoIFkA5OnSQXnvNzp95Rho3jmmoAFAZBAugApdfLo0ZY+cjR9rgzrw8d2sCgGBHsAAO4YEHpOeek6KipH//Wzr/fGnXLrerAoDgRbAADuP226UPP5Rq1ZJmzJC6d5dWr3a7KgAITgQLoBIuuECaO9dW6Vy1SurWTZo92+2qACD4ECyASurQQfruO+mUU2x9i3POsR1SAQAlCBZAFTRuLM2cKQ0YIOXnS9dfL913n1RU5HZlABAcCBZAFSUkSFOmSPfea48feUS68UbCBQBIBAugWqKiLFD85z9STIzdErn/frerAgD3ESyAI3D99dIrr9j5o49KL7/sbj0A4DaCBXCErr9eGj3azocMkT7/3N16AMBNBAvAB0aPlq69VioslPr3l374we2KAMAdBAvABzweuyXi3XL9wguljRvdrgoAAo9gAfhIXJw0bZrUtq30++8WLjIz3a4KAAKLYAH4UO3a0scfS40aSUuXSldcYetdAECkIFgAPnbMMdJHH0mJiTaQ89Zb2XIdQOQgWAB+0KWLLaIVFWVjL9LS3K4IAAKDYAH4yUUXSc8+a+ejRklXXy3t2OFuTQDgbwQLwI9uu016+GHruXjzTRvY+dZb3BoBEL4IFoCfjRolzZ8vtWsnbd8uXXmldPnl0pYtblcGAL5HsAACoGtX6fvvbSGtmBjp3Xet9+L11+m9ABBeCBZAgMTFSQ8+KC1cKHXqJO3aZcuBX3ihtGGD29UBgG8QLIAA69hR+vZbmykSHy99+ql04onSf//rdmUAcOQIFoALYmKkESOkxYulHj2krCzpuuukG2+UsrPdrg4Aqo9gAbioTRvp66+lMWNs5sh//mPjMZYtc7syAKgeggXgsuho6YEHpK++ko46SvrpJ+mUU6SXX2ZgJ4DQQ7AAgsQZZ9h26+efL+3bJ918sy2qxUZmAEIJwQIIIg0a2CZmjz1mPRlTptgMkkWL3K4MACqHYAEEmago6e9/t7EXzZpJa9bYAM+nn5YKC92uDgAOjWABBKkePWzWSL9+Ul6e9Ne/St260XsBILgRLIAgVreurdL5r39JKSm2emfXrhYy9uxxuzoAOBjBAghyHo8N5Pz5Z2ngQKmoyG6LtG0rffih29UBQFkECyBENG5sO6R+8ol0zDG2DPjFF0v9+0u//+52dQBgCBZAiOnbV1q+3AZ4RkdL77xjC20995xNUwUANxEsgBCUmGhTUhctsgGdWVnSnXfaLJLRo6WtW92uEECkIlgAIaxDB2nuXGn8eAsV27dLDz1k5zfeKC1d6naFACINwQIIcdHR0uDBtt7F1KlS9+42PfU//7GdVM8+W/roIxv0CQD+RrAAwkRMjHTFFdI331i74goLHdOnSxddZOMwHn9cWr/e7UoBhDOCBRCGune33ou1a6W777Y1MFatku65R2reXOrd29bG2LnT7UoBhBuP4wR2/8TMzEylpKQoIyNDycnJgXxpIGJlZdm+I5MnS7NmleyaGhNjm55dfbVNXa1Z0906AQSvyr5/EyyACLNhg/VmvPGGtGRJyfOJiXb7ZNgwG5sBAKURLAAc1ooVtujW5Ml228TrrLOku+6SLrjANkUDgMq+f/MrA4hgbdtKY8dKq1dLc+aUP+DzxRel7Gy3KwUQKggWAOTxSD17lh3wmZxsAz6HDpVSU6WRI6WNG92uFECw41YIgHJlZUkTJ0rPPlv2NslJJ9naGGedZbNLatVyrUQAAcQYCwA+UVhou6j+4x/S7NllPxYTY0uKe4NG9+5SfLw7dQLwL4IFAJ/butXGX3z1lbXffiv78YQEm1HSoYO1jh2l9u1tHQ0AoY1gAcDv1q4tCRrTp0vbtpX/ec2blwSOtm2l446zVqdOYOsFUH0ECwAB5TjSzz9LP/xgm59524YNFX9N3bpSy5YlQeO442wDtZo1rffD22rUKDl6PIH7bwJQgmABICjs2iUtW2Yh44cfbKbJ6tXSpk3V+34JCVLjxhZAmjWzGSulj82a2YwWAL5FsAAQ1LKz7VbK6tXW1qyx48aNUk5O2VZYWLXvnZhovSH16lnznpc+1qkj1a5d9piURI8IUJHKvn/HBLAmAChWs6YN7Gzf/vCfm59vAWPfPgskmzbZLq3r19utltLnf/wh7d1rrarrbkRFWcg4XKtTx1r9+tYaNCCUAF7VChYvvviinnjiCW3evFknnniinnnmGfXq1cvXtQGAJCk21pr3j6QWLWxBr/Ls2WODSHfutJBR+lj6fPdua7t2WcvLk4qK7ON//FG9Gr1Bo3596xWJiioJGx5PSfM+TkiwQFKrlh1Ln9eqZR+PjrbvExVVcl76mJhoIS0x0ab6Em7gtioHi6lTp2rYsGF68cUX1bNnT/3rX/9S3759tWLFCjVr1swfNQJApdWqZe3YY6v2dfv2WcDwho2MjJLHBzZvGNm+Xdqxw3pH8vOlzZutuSUqqiRk1KxpLS7O1hvxtujoso9LP3fg0Xte+vnSrfTnesPfoZr3e5Z3HhdXfouOJiyFmiqPsejWrZs6deqk8ePHFz/Xpk0bXXLJJUpLSzvs1zPGAkC42bvXekG8QWPHDgsejlPSpLLHoiK7vbNnj61y6m2lH+/bZ5/nbYWFZc8LCux75OW599/ubx5PScDwPvYeDzwvHVjKa96enwObtweodIAp/b1Lv8ahQpq3Ru//3/KOUkkwK68XKiqq7M9JeT8/h6rRe3z4Yd8PYvbLGIu8vDx9//33GjFiRJnn+/Tpo3nz5pX7Nbm5ucrNzS1TGACEk8REa6mp7rx+fn7JuJLsbGve8/x8CyAHNm8wyc+3c+9j77H0eeljeefe71O65eWVfVz69Q6spfTXHBiSHEcq9RaCSho1yr3ZUVUKFjt27FBhYaEaNWpU5vlGjRppy5Yt5X5NWlqaxowZU/0KAQCHFBtrq5uGwwqnjmNhwxsy8vIsWJT+i7+8v+IPDDrlhZfSvT8HtsLC8nsGSp+X7imqqEklvR8HHr09CuX1PpU+VtQrU/pYurby6q5Zs3rX3xeqNXjTc8ANL8dxDnrOa+TIkRo+fHjx48zMTKW6FesBAEHNe0sjNtbdN0dUX5WCRf369RUdHX1Q78S2bdsO6sXwio+PVzy7EgEAEBGiqvLJcXFx6ty5s9LT08s8n56erlNPPdWnhQEAgNBT5Vshw4cP17XXXqsuXbqoR48emjBhgtavX6/Bgwf7oz4AABBCqhwsrrzySu3cuVMPPfSQNm/erHbt2umTTz5R8+bN/VEfAAAIIewVAgAADquy799VGmMBAABwKAQLAADgMwQLAADgMwQLAADgMwQLAADgMwQLAADgMwQLAADgMwQLAADgM9Xa3fRIeNfjyszMDPRLAwCAavK+bx9uXc2AB4usrCxJYut0AABCUFZWllJSUir8eMCX9C4qKtKmTZuUlJQkj8fjs++bmZmp1NRUbdiwgaXCfYDr6TtcS9/ievoO19K3wv16Oo6jrKwsNWnSRFFRFY+kCHiPRVRUlJo2beq375+cnByW/0PdwvX0Ha6lb3E9fYdr6VvhfD0P1VPhxeBNAADgMwQLAADgM2ETLOLj4zV69GjFx8e7XUpY4Hr6DtfSt7ievsO19C2upwn44E0AABC+wqbHAgAAuI9gAQAAfIZgAQAAfIZgAQAAfCZsgsWLL76oFi1aqEaNGurcubO+/vprt0sKerNnz9ZFF12kJk2ayOPx6L333ivzccdx9OCDD6pJkyZKSEjQGWecoeXLl7tTbJBLS0tT165dlZSUpIYNG+qSSy7RypUry3wO17Pyxo8frw4dOhQvNNSjRw99+umnxR/nWlZfWlqaPB6Phg0bVvwc17PyHnzwQXk8njKtcePGxR/nWoZJsJg6daqGDRumUaNGafHixerVq5f69u2r9evXu11aUMvOzlbHjh31wgsvlPvxxx9/XE8//bReeOEFLViwQI0bN9a5555bvN8LSsyaNUtDhw7V/PnzlZ6eroKCAvXp00fZ2dnFn8P1rLymTZtq3LhxWrhwoRYuXKizzjpL/fr1K/4FzbWsngULFmjChAnq0KFDmee5nlVz4oknavPmzcVt2bJlxR/jWkpywsApp5ziDB48uMxzrVu3dkaMGOFSRaFHkvPuu+8WPy4qKnIaN27sjBs3rvi5ffv2OSkpKc5LL73kQoWhZdu2bY4kZ9asWY7jcD19oU6dOs4rr7zCtaymrKws5/jjj3fS09Od008/3bnzzjsdx+Fns6pGjx7tdOzYsdyPcS1NyPdY5OXl6fvvv1efPn3KPN+nTx/NmzfPpapC36+//qotW7aUua7x8fE6/fTTua6VkJGRIUmqW7euJK7nkSgsLNSUKVOUnZ2tHj16cC2raejQobrwwgt1zjnnlHme61l1v/zyi5o0aaIWLVpo4MCBWrt2rSSupVfANyHztR07dqiwsFCNGjUq83yjRo20ZcsWl6oKfd5rV951XbdunRslhQzHcTR8+HCddtppateunSSuZ3UsW7ZMPXr00L59+1SrVi29++67atu2bfEvaK5l5U2ZMkWLFi3SggULDvoYP5tV061bN73++us64YQTtHXrVj388MM69dRTtXz5cq7lfiEfLLwO3ILdcRyfbsseqbiuVXfbbbdp6dKlmjNnzkEf43pWXqtWrbRkyRLt3r1b77zzjq6//nrNmjWr+ONcy8rZsGGD7rzzTn3xxReqUaNGhZ/H9aycvn37Fp+3b99ePXr0UMuWLfXaa6+pe/fukriWIX8rpH79+oqOjj6od2Lbtm0HpUZUnneUM9e1am6//XZ98MEHmjFjhpo2bVr8PNez6uLi4nTcccepS5cuSktLU8eOHfXss89yLavo+++/17Zt29S5c2fFxMQoJiZGs2bN0nPPPaeYmJjia8b1rJ6aNWuqffv2+uWXX/jZ3C/kg0VcXJw6d+6s9PT0Ms+np6fr1FNPdamq0NeiRQs1bty4zHXNy8vTrFmzuK7lcBxHt912m6ZNm6bp06erRYsWZT7O9TxyjuMoNzeXa1lFZ599tpYtW6YlS5YUty5dumjQoEFasmSJjj32WK7nEcjNzdVPP/2ko446ip9NL9eGjfrQlClTnNjYWOfVV191VqxY4QwbNsypWbOm89tvv7ldWlDLyspyFi9e7CxevNiR5Dz99NPO4sWLnXXr1jmO4zjjxo1zUlJSnGnTpjnLli1zrrrqKueoo45yMjMzXa48+AwZMsRJSUlxZs6c6WzevLm47d27t/hzuJ6VN3LkSGf27NnOr7/+6ixdutS59957naioKOeLL75wHIdreaRKzwpxHK5nVfz1r391Zs6c6axdu9aZP3++86c//clJSkoqfr/hWjpOWAQLx3Gcf/7zn07z5s2duLg4p1OnTsXT/FCxGTNmOJIOatdff73jODZ1avTo0U7jxo2d+Ph4p3fv3s6yZcvcLTpIlXcdJTkTJ04s/hyuZ+XddNNNxf+eGzRo4Jx99tnFocJxuJZH6sBgwfWsvCuvvNI56qijnNjYWKdJkybOZZdd5ixfvrz441xLx2HbdAAA4DMhP8YCAAAED4IFAADwGYIFAADwGYIFAADwGYIFAADwGYIFAADwGYIFAADwGYIFAADwGYIFAADwGYIFAADwGYIFAADwGYIFAADwmf8HV9xAQP2dma8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.arange(len(train_losses)), train_losses, 'b')\n",
    "plt.plot(np.arange(len(train_losses)), val_losses, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "113c1af4-31d9-4d85-8337-95d1061e6321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [0.1, 0.4, 0.2, 0.3, 0.1]\n",
    "\n",
    "def generate_text_simple(idx, temp):\n",
    "    for _ in range(1):\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     logits = model(idx_cond)\n",
    "\n",
    "        logits = torch.tensor(idx)\n",
    "        scaled_logits = logits/(temp)\n",
    "        \n",
    "        probas = torch.softmax(scaled_logits, dim=-1)\n",
    "        \n",
    "        idx_next = torch.multinomial(probas, num_samples=1)\n",
    "\n",
    "        # idx = torch.cat((idx,idx_next), dim=1)\n",
    "\n",
    "    return idx_next\n",
    "\n",
    "generate_text_simple(idx, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "df79644c-8bc4-4853-9bb4-b0f8b686c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_using_temperature_scaling(model, temp, idx, max_new_tokens, context_size):\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        scaled_logits = logits/(temp)\n",
    "        \n",
    "        probas = torch.softmax(scaled_logits, dim=-1)\n",
    "        \n",
    "        idx_next = torch.multinomial(probas, num_samples=1)\n",
    "\n",
    "        idx = torch.cat((idx,idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "fde5cf3e-e57d-4174-bb01-0eb6f6558e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every effort moves you?\"  \"Yes--quite,\" she said'"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = decoding_using_temperature_scaling(model, 0.9, text_to_token_ids(start_context, tokenizer),\n",
    "                                           10, 124)\n",
    "token_ids_to_text(tokens, tokenizer).replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "aa201d97-28e2-4781-8355-d80fb44d4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_using_temp_scaling_and_topk(model, temp, k, idx, max_new_tokens, context_size, eos_idx=None):\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        if k is not None:\n",
    "            values, _ = torch.topk(logits, k=k)\n",
    "            logits = torch.where(logits<values[:, -1], torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        if temp>0.0:\n",
    "            logits = logits/(temp)\n",
    "        \n",
    "            probas = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probas, num_samples=1)\n",
    "\n",
    "        else:\n",
    "            idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "            \n",
    "        if idx_next==eos_idx:\n",
    "            break\n",
    "        idx = torch.cat((idx,idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "76d481ce-129f-4f7d-8e08-c2d31b4cca4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here down we if I\\'d never touched a brush.\"\\n\\nAnd his tone told me'"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = decoding_using_temp_scaling_and_topk(model, .8, 3, \n",
    "                                    idx = text_to_token_ids(\"Here down we\", tokenizer),\n",
    "                                    max_new_tokens=15, \n",
    "                                    context_size = GPT_CONFIG_124M[\"context_length\"])\n",
    "\n",
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "0cd9bba1-b94a-4509-992c-13e0cfec79bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x3e5ccece0>"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e3eb4d-d074-49cf-87a3-e1eee30d5c21",
   "metadata": {},
   "source": [
    "# Saving and loading model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "b48ecaca-e624-43fc-9bb3-b4e4679d49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\":model.state_dict(), \n",
    "    \"optimizer_state_dict\":optimizer.state_dict()}, \n",
    "    \"model.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0edef8-4807-4084-85d6-7dc7ba0282fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = torch.optim.AdamW(lr=4e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
